{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "583f4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from dataset import MaskBaseDataset\n",
    "from loss import create_criterion\n",
    "\n",
    "import loss\n",
    "import utils\n",
    "from pprint import pprint\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def grid_image(np_images, gts, preds, n=16, shuffle=False):\n",
    "    batch_size = np_images.shape[0]\n",
    "    assert n <= batch_size\n",
    "\n",
    "    choices = random.choices(range(batch_size), k=n) if shuffle else list(range(n))\n",
    "    figure = plt.figure(figsize=(12, 18 + 2))  # cautions: hardcoded, 이미지 크기에 따라 figsize 를 조정해야 할 수 있습니다. T.T\n",
    "    plt.subplots_adjust(top=0.8)               # cautions: hardcoded, 이미지 크기에 따라 top 를 조정해야 할 수 있습니다. T.T\n",
    "    n_grid = np.ceil(n ** 0.5)\n",
    "    tasks = [\"mask\", \"gender\", \"age\"]\n",
    "    for idx, choice in enumerate(choices):\n",
    "        gt = gts[choice].item()\n",
    "        pred = preds[choice].item()\n",
    "        image = np_images[choice]\n",
    "        # title = f\"gt: {gt}, pred: {pred}\"\n",
    "        gt_decoded_labels = MaskBaseDataset.decode_multi_class(gt)\n",
    "        pred_decoded_labels = MaskBaseDataset.decode_multi_class(pred)\n",
    "        title = \"\\n\".join([\n",
    "            f\"{task} - gt: {gt_label}, pred: {pred_label}\"\n",
    "            for gt_label, pred_label, task\n",
    "            in zip(gt_decoded_labels, pred_decoded_labels, tasks)\n",
    "        ])\n",
    "\n",
    "        plt.subplot(n_grid, n_grid, idx + 1, title=title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "\n",
    "    return figure\n",
    "\n",
    "\n",
    "def increment_path(path, exist_ok=False):\n",
    "    \"\"\" Automatically increment path, i.e. runs/exp --> runs/exp0, runs/exp1 etc.\n",
    "\n",
    "    Args:\n",
    "        path (str or pathlib.Path): f\"{model_dir}/{args.name}\".\n",
    "        exist_ok (bool): whether increment path (increment if False).\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a21d6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b31020fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_module = getattr(import_module(\"dataset\"), 'MaskBaseDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "535bbe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_module(\n",
    "        data_dir='/opt/ml/input/data/train/images',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80bd6a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b55162e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_module = getattr(import_module(\"dataset\"), 'BaseAugmentation')  # default: BaseAugmentation\n",
    "transform = transform_module(\n",
    "    resize=(224,224),\n",
    "    mean=dataset.mean,\n",
    "    std=dataset.std,\n",
    ")\n",
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f583896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_module = getattr(import_module(\"model\"), 'ConvNextIn22ft1k')  # default: BaseModel\n",
    "model = model_module(\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c51dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = dataset.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1cd1ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=32,\n",
    "    num_workers=multiprocessing.cpu_count()//2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "06db9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_pred = []\n",
    "f1_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a1c46908",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ee5b6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b912236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3234c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(outs, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e42e9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_pred += preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5c1e4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_labels += labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "205fb15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "32d862a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c19e9268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(16, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(11, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(15, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(5, device='cuda:0'),\n",
       " tensor(16, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(11, device='cuda:0'),\n",
       " tensor(15, device='cuda:0'),\n",
       " tensor(11, device='cuda:0'),\n",
       " tensor(5, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(12, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(16, device='cuda:0'),\n",
       " tensor(11, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(11, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(2, device='cuda:0'),\n",
       " tensor(5, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(7, device='cuda:0'),\n",
       " tensor(13, device='cuda:0')]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4c0f1c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(4, device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'),\n",
       " tensor(7, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'),\n",
       " tensor(3, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(15, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'),\n",
       " tensor(13, device='cuda:0'),\n",
       " tensor(5, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'),\n",
       " tensor(11, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " tensor(3, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(2, device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(3, device='cuda:0'),\n",
       " tensor(4, device='cuda:0'),\n",
       " tensor(14, device='cuda:0'),\n",
       " tensor(10, device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " tensor(15, device='cuda:0'),\n",
       " tensor(3, device='cuda:0')]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4312c4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  1,  1,  4,  1,  4,  7,  4,  3,  0, 15,  4,  4, 13,  5,  4, 11, 10,\n",
       "         1,  3,  0,  2,  1, 10,  0,  3,  4, 14, 10,  1, 15,  3],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_labels = torch.stack(f1_labels)\n",
    "f1_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "905511c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_labels = f1_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1b5da869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  1,  1,  4,  1,  4,  7,  4,  3,  0, 15,  4,  4, 13,  5,  4, 11,\n",
       "       10,  1,  3,  0,  2,  1, 10,  0,  3,  4, 14, 10,  1, 15,  3])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "070c4aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 10, 16, 13, 10, 13, 11, 13, 15, 13,  5, 16, 13, 11, 15, 11,  5,\n",
       "       10, 12, 10, 16, 11, 10, 11, 10, 13, 13,  2,  5, 13,  7, 13])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_pred = torch.stack(f1_pred)\n",
    "f1_pred = f1_pred.cpu().numpy()\n",
    "f1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93df26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ed1b67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro = f1_score(f1_labels, f1_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "75c499e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015873015873015872"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428c5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
