{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b05616ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e875bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b126f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4156a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\",\n",
    "    \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bb5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491971ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAugmentation:\n",
    "    def __init__(self, resize, mean, std, **args):\n",
    "        self.transform = transforms.Compose([\n",
    "            Resize(resize, Image.BILINEAR),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da911e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    \"\"\"\n",
    "        transform 에 없는 기능들은 이런식으로 __init__, __call__, __repr__ 부분을\n",
    "        직접 구현하여 사용할 수 있습니다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28978de",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AddGaussianNoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321e5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddGaussianNoise(mean=0.0, std=1.0)\n"
     ]
    }
   ],
   "source": [
    "# def __repr__(self):\n",
    "#    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc6cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugmentation:\n",
    "    def __init__(self, resize, mean, std, **args):\n",
    "        self.transform = transforms.Compose([\n",
    "            CenterCrop((320, 256)),\n",
    "            Resize(resize, Image.BILINEAR),\n",
    "            ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "            AddGaussianNoise()\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a736394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2869292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enum.EnumMeta"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(MaskLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81fd58b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskLabels.MASK\n",
      "MaskLabels.INCORRECT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MaskLabels.NORMAL: 2>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MaskLabels.MASK)\n",
    "print(MaskLabels.INCORRECT)\n",
    "MaskLabels.NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3acbddab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskLabels.MASK\n",
      "MaskLabels.INCORRECT\n",
      "MaskLabels.NORMAL\n"
     ]
    }
   ],
   "source": [
    "for m in MaskLabels:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb825410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0377060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad4ad7",
   "metadata": {},
   "source": [
    "GenderLabels.from_str('male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b9f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskBaseDataset(Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, data_dir, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), val_ratio=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "        self.transform = None\n",
    "        self.setup()\n",
    "        self.calc_statistics()\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.data_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.data_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "\n",
    "    def calc_statistics(self):\n",
    "        has_statistics = self.mean is not None and self.std is not None\n",
    "        if not has_statistics:\n",
    "            print(\"[Warning] Calculating statistics... It can take a long time depending on your CPU machine\")\n",
    "            sums = []\n",
    "            squared = []\n",
    "            for image_path in self.image_paths[:3000]:\n",
    "                image = np.array(Image.open(image_path)).astype(np.int32)\n",
    "                sums.append(image.mean(axis=(0, 1)))\n",
    "                squared.append((image ** 2).mean(axis=(0, 1)))\n",
    "\n",
    "            self.mean = np.mean(sums, axis=0) / 255\n",
    "            self.std = (np.mean(squared, axis=0) - self.mean ** 2) ** 0.5 / 255\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert self.transform is not None, \".set_tranform 메소드를 이용하여 transform 을 주입해주세요\"\n",
    "\n",
    "        image = self.read_image(index)\n",
    "        mask_label = self.get_mask_label(index)\n",
    "        gender_label = self.get_gender_label(index)\n",
    "        age_label = self.get_age_label(index)\n",
    "        multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "\n",
    "        image_transform = self.transform(image)\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def get_mask_label(self, index) -> MaskLabels:\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index) -> GenderLabels:\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index) -> AgeLabels:\n",
    "        return self.age_labels[index]\n",
    "\n",
    "    def read_image(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_multi_class(multi_class_label) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "        mask_label = (multi_class_label // 6) % 3\n",
    "        gender_label = (multi_class_label // 3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize_image(image, mean, std):\n",
    "        img_cp = image.copy()\n",
    "        img_cp *= std\n",
    "        img_cp += mean\n",
    "        img_cp *= 255.0\n",
    "        img_cp = np.clip(img_cp, 0, 255).astype(np.uint8)\n",
    "        return img_cp\n",
    "\n",
    "    def split_dataset(self) -> Tuple[Subset, Subset]:\n",
    "        \"\"\"\n",
    "        데이터셋을 train 과 val 로 나눕니다,\n",
    "        pytorch 내부의 torch.utils.data.random_split 함수를 사용하여\n",
    "        torch.utils.data.Subset 클래스 둘로 나눕니다.\n",
    "        구현이 어렵지 않으니 구글링 혹은 IDE (e.g. pycharm) 의 navigation 기능을 통해 코드를 한 번 읽어보는 것을 추천드립니다^^\n",
    "        \"\"\"\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = random_split(self, [n_train, n_val])\n",
    "        return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train/images'\n",
    "profiles = os.listdir(data_dir)\n",
    "# print(profiles)\n",
    "\n",
    "def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "    return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "_file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "}\n",
    "image_paths = []\n",
    "mask_labels = []\n",
    "gender_labels = []\n",
    "age_labels = []\n",
    "\n",
    "multi_label_dict = defaultdict(list)\n",
    "\n",
    "cnt = 0\n",
    "for profile in profiles:\n",
    "    if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "        continue\n",
    "\n",
    "    img_folder = os.path.join(data_dir, profile)\n",
    "\n",
    "    for file_name in os.listdir(img_folder):\n",
    "        _file_name, ext = os.path.splitext(file_name)\n",
    "        if _file_name not in _file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "            continue\n",
    "        img_path = os.path.join(data_dir, profile, file_name)\n",
    "        mask_label = _file_names[_file_name]\n",
    "\n",
    "        id, gender, race, age = profile.split(\"_\")\n",
    "        gender_label = GenderLabels.from_str(gender)\n",
    "        age_label = AgeLabels.from_number(age)\n",
    "\n",
    "        image_paths.append(img_path)\n",
    "        mask_labels.append(mask_label)\n",
    "        gender_labels.append(gender_label)\n",
    "        age_labels.append(age_label)\n",
    "        multi_class_label = encode_multi_class(mask_label, gender_label, age_label)\n",
    "        multi_label_dict[multi_class_label].append(cnt)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df74034",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in multi_label_dict.items():\n",
    "    print(f'key : {key}, len(value) : {len(value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "val_indices = []\n",
    "        \n",
    "for key, value in multi_label_dict.items():\n",
    "    n_val = int(len(value) * 0.2)\n",
    "    random.shuffle(value)\n",
    "    key_val_indices = value[:n_val]\n",
    "    key_train_indices = value[n_val:]\n",
    "    \n",
    "    train_indices.append(key_train_indices)\n",
    "    val_indices.append(key_val_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(train_indices) |set(val_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bed47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "for key, value in multi_label_dict.items():\n",
    "    print(f'{key} : {len(value)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskStratifiedDataset(Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "    multi_label_dict = defaultdict(list)\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, data_dir, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), val_ratio=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "        self.transform = None\n",
    "        self.setup()\n",
    "        self.calc_statistics()\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        indice = 0\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.data_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.data_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "                \n",
    "                multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "                self.multi_label_dict[multi_class_label].append(indice)\n",
    "                indice += 1\n",
    "\n",
    "    def calc_statistics(self):\n",
    "        has_statistics = self.mean is not None and self.std is not None\n",
    "        if not has_statistics:\n",
    "            print(\"[Warning] Calculating statistics... It can take a long time depending on your CPU machine\")\n",
    "            sums = []\n",
    "            squared = []\n",
    "            for image_path in self.image_paths[:3000]:\n",
    "                image = np.array(Image.open(image_path)).astype(np.int32)\n",
    "                sums.append(image.mean(axis=(0, 1)))\n",
    "                squared.append((image ** 2).mean(axis=(0, 1)))\n",
    "\n",
    "            self.mean = np.mean(sums, axis=0) / 255\n",
    "            self.std = (np.mean(squared, axis=0) - self.mean ** 2) ** 0.5 / 255\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert self.transform is not None, \".set_tranform 메소드를 이용하여 transform 을 주입해주세요\"\n",
    "\n",
    "        image = self.read_image(index)\n",
    "        mask_label = self.get_mask_label(index)\n",
    "        gender_label = self.get_gender_label(index)\n",
    "        age_label = self.get_age_label(index)\n",
    "        multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "\n",
    "        image_transform = self.transform(image)\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def get_mask_label(self, index) -> MaskLabels:\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index) -> GenderLabels:\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index) -> AgeLabels:\n",
    "        return self.age_labels[index]\n",
    "\n",
    "    def read_image(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_multi_class(multi_class_label) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "        mask_label = (multi_class_label // 6) % 3\n",
    "        gender_label = (multi_class_label // 3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize_image(image, mean, std):\n",
    "        img_cp = image.copy()\n",
    "        img_cp *= std\n",
    "        img_cp += mean\n",
    "        img_cp *= 255.0\n",
    "        img_cp = np.clip(img_cp, 0, 255).astype(np.uint8)\n",
    "        return img_cp\n",
    "\n",
    "    def split_dataset(self) -> Tuple[Subset, Subset]:\n",
    "        \"\"\"\n",
    "        데이터셋을 train 과 val 로 나눕니다,\n",
    "        pytorch 내부의 torch.utils.data.random_split 함수를 사용하여\n",
    "        torch.utils.data.Subset 클래스 둘로 나눕니다.\n",
    "        구현이 어렵지 않으니 구글링 혹은 IDE (e.g. pycharm) 의 navigation 기능을 통해 코드를 한 번 읽어보는 것을 추천드립니다^^\n",
    "        \"\"\"\n",
    "        train_indices = []\n",
    "        val_indices = []\n",
    "\n",
    "        for key, value in self.multi_label_dict.items():\n",
    "            n_val = int(len(value) * 0.2)\n",
    "            random.shuffle(value)\n",
    "            key_val_indices = value[:n_val]\n",
    "            key_train_indices = value[n_val:]\n",
    "\n",
    "            val_indices += key_val_indices\n",
    "            train_indices += key_train_indices\n",
    "            \n",
    "            random.shuffle(val_indices)\n",
    "            random.shuffle(train_indices)\n",
    "            \n",
    "        return Subset(self, train_indices), Subset(self, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c549a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskStratifiedDataset(MaskBaseDataset):\n",
    "    def __init__(self, data_dir, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), val_ratio=0.2):\n",
    "        self.multi_label_dict = defaultdict(list)\n",
    "        super().__init__(data_dir, mean, std, val_ratio)\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        indice = 0\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.data_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.data_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "                \n",
    "                multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "                self.multi_label_dict[multi_class_label].append(indice)\n",
    "                indice += 1\n",
    "\n",
    "    def split_dataset(self) -> Tuple[Subset, Subset]:\n",
    "        \"\"\"\n",
    "        데이터셋을 target 의 비율로 나눕니다.\n",
    "        \"\"\"\n",
    "        train_indices = []\n",
    "        val_indices = []\n",
    "\n",
    "        for key, value in self.multi_label_dict.items():\n",
    "            n_val = int(len(value) * self.val_ratio)\n",
    "            random.shuffle(value)\n",
    "            key_val_indices = value[:n_val]\n",
    "            key_train_indices = value[n_val:]\n",
    "\n",
    "            val_indices += key_val_indices\n",
    "            train_indices += key_train_indices\n",
    "            \n",
    "            random.shuffle(val_indices)\n",
    "            random.shuffle(train_indices)\n",
    "            \n",
    "        return Subset(self, train_indices), Subset(self, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "084e416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAugmentation:\n",
    "    def __init__(self, resize, mean, std, **args):\n",
    "        self.transform = transforms.Compose([\n",
    "            Resize(resize, Image.BILINEAR),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e508bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaskStratifiedDataset('/opt/ml/input/data/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b79d32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_module = BaseAugmentation\n",
    "\n",
    "transform = transform_module(\n",
    "        resize=[128,128],\n",
    "        mean=dataset.mean,\n",
    "        std=dataset.std,\n",
    "    )\n",
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f67c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = dataset.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f3fd891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15126"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d17a564c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3774"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30713bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f09de61f9a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ae69f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f094347a700>, {})\n"
     ]
    }
   ],
   "source": [
    "train_dist = defaultdict(lambda:0)\n",
    "print(train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "530c6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist = defaultdict(lambda:0)\n",
    "for i, x in enumerate(train_data):\n",
    "    train_dist[x[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f90b73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dist = defaultdict(lambda:0)\n",
    "for i, x in enumerate(val_data):\n",
    "    val_dist[x[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d32cb187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "axes[0].bar(train_dist.keys(), train_dist.values(), color='royalblue')\n",
    "axes[1].bar(val_dist.keys(), val_dist.values(), color='tomato')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1330e51b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
